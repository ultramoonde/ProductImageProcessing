#!/usr/bin/env python3
"""
Background Product Enrichment Worker
- Works like a pizza order system: submit request, get results later
- Progressively enriches product data from sparse to rich
- Handles German food retailers (Rewe, Flink, Edeka, etc.)
- Produces 1024x1024 transparent product images
"""

import asyncio
import json
import time
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import requests
from dataclasses import dataclass, asdict
import sqlite3
import threading
from queue import Queue, Empty
import cv2
import numpy as np
from PIL import Image, ImageEnhance
import io
import re

# Import our existing services
from product_enrichment_service import ProductEnrichmentService
from background_removal_service import BackgroundRemovalService


@dataclass
class ProductEnrichmentRequest:
    """Data structure for enrichment requests"""
    request_id: str
    user_session_id: str
    product_name: str
    brand: str = ""
    weight_quantity: str = ""
    price: str = ""
    category: str = ""
    source_context: str = ""  # "pantry_add", "meal_log", "spontaneous_capture"
    priority: int = 1  # 1=high, 2=medium, 3=low
    created_at: str = ""
    
    def __post_init__(self):
        if not self.created_at:
            self.created_at = datetime.now().isoformat()
        if not self.request_id:
            self.request_id = self._generate_id()
    
    def _generate_id(self) -> str:
        data = f"{self.product_name}{self.brand}{self.weight_quantity}{time.time()}"
        return hashlib.sha256(data.encode()).hexdigest()[:16]


@dataclass
class EnrichedProductData:
    """Complete enriched product information"""
    request_id: str
    product_signature: str
    
    # Original data
    original_name: str
    original_brand: str
    original_weight: str
    
    # Enriched identification
    official_name: str = ""
    official_brand: str = ""
    manufacturer: str = ""
    ean_barcode: str = ""
    
    # Nutritional information
    calories_per_100g: str = ""
    protein_per_100g: str = ""
    carbs_per_100g: str = ""
    fat_per_100g: str = ""
    fiber_per_100g: str = ""
    sugar_per_100g: str = ""
    salt_per_100g: str = ""
    
    # Allergens and dietary info
    allergens: List[str] = None
    dietary_flags: List[str] = None  # vegan, vegetarian, gluten-free, etc.
    ingredients_list: str = ""
    
    # Images (URLs and local paths)
    high_res_image_url: str = ""
    image_urls: List[str] = None  # All collected product images
    processed_image_path: str = ""  # 1024x1024 transparent
    thumbnail_path: str = ""  # 256x256 for quick loading
    
    # Source information
    source_retailer: str = ""
    source_url: str = ""
    price_info: Dict[str, str] = None
    
    # Processing metadata
    enrichment_level: str = "basic"  # basic, moderate, complete
    enrichment_score: float = 0.0  # 0-100, how much data we have
    processing_attempts: int = 0
    last_updated: str = ""
    next_retry_at: str = ""
    
    def __post_init__(self):
        if self.allergens is None:
            self.allergens = []
        if self.dietary_flags is None:
            self.dietary_flags = []
        if self.image_urls is None:
            self.image_urls = []
        if self.price_info is None:
            self.price_info = {}
        if not self.last_updated:
            self.last_updated = datetime.now().isoformat()


class BackgroundEnrichmentWorker:
    """
    Background service that progressively enriches product data
    Works asynchronously to build comprehensive product profiles
    """
    
    def __init__(self, storage_dir: str = "enriched_products"):
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # Database for tracking requests and results
        self.db_path = self.storage_dir / "enrichment_database.db"
        self.init_database()
        
        # Work queues
        self.high_priority_queue = Queue()
        self.medium_priority_queue = Queue()
        self.low_priority_queue = Queue()
        
        # Services
        self.enrichment_service = ProductEnrichmentService(str(self.storage_dir))
        self.bg_removal_service = BackgroundRemovalService()
        
        # Logging callback
        self.log_callback = None
        
        # User interaction callbacks
        self.question_callback = None
        self.response_callback = None
        
        # Worker state
        self.worker_thread = None
        self.is_running = False
        self.stats = {
            'requests_processed': 0,
            'successful_enrichments': 0,
            'failed_enrichments': 0,
            'cache_hits': 0,
            'images_processed': 0
        }
        
        # Image processing directories
        self.images_dir = self.storage_dir / "product_images"
        self.images_dir.mkdir(parents=True, exist_ok=True)
        
        self.processed_images_dir = self.storage_dir / "processed_images"
        self.processed_images_dir.mkdir(parents=True, exist_ok=True)
        
        self.thumbnails_dir = self.storage_dir / "thumbnails"
        self.thumbnails_dir.mkdir(parents=True, exist_ok=True)
    
    def init_database(self):
        """Initialize SQLite database for tracking requests and results"""
        with sqlite3.connect(str(self.db_path)) as conn:
            conn.executescript('''
                CREATE TABLE IF NOT EXISTS enrichment_requests (
                    request_id TEXT PRIMARY KEY,
                    user_session_id TEXT,
                    product_name TEXT,
                    brand TEXT,
                    weight_quantity TEXT,
                    priority INTEGER,
                    status TEXT DEFAULT 'pending',
                    created_at TEXT,
                    started_at TEXT,
                    completed_at TEXT,
                    error_message TEXT
                );
                
                CREATE TABLE IF NOT EXISTS enriched_products (
                    product_signature TEXT PRIMARY KEY,
                    request_id TEXT,
                    enriched_data TEXT,  -- JSON blob
                    enrichment_level TEXT,
                    enrichment_score REAL,
                    created_at TEXT,
                    updated_at TEXT,
                    FOREIGN KEY (request_id) REFERENCES enrichment_requests (request_id)
                );
                
                CREATE TABLE IF NOT EXISTS user_product_cache (
                    user_session_id TEXT,
                    product_signature TEXT,
                    last_accessed TEXT,
                    access_count INTEGER DEFAULT 1,
                    PRIMARY KEY (user_session_id, product_signature)
                );
                
                CREATE INDEX IF NOT EXISTS idx_status_priority ON enrichment_requests(status, priority);
                CREATE INDEX IF NOT EXISTS idx_user_cache ON user_product_cache(user_session_id, last_accessed);
            ''')
    
    def submit_enrichment_request(self, request: ProductEnrichmentRequest) -> str:
        """
        Submit a product for background enrichment
        Returns immediately with request ID
        """
        print(f"üçï New enrichment request: {request.product_name}")
        
        # Check if we already have this product enriched
        product_signature = self._create_product_signature(
            request.product_name, request.brand, request.weight_quantity
        )
        
        existing_data = self._get_cached_product(product_signature)
        if existing_data:
            print(f"   üìã Using cached data for {request.product_name}")
            self._update_user_cache(request.user_session_id, product_signature)
            self.stats['cache_hits'] += 1
            
            # Store request as completed since we have cached data
            with sqlite3.connect(str(self.db_path)) as conn:
                conn.execute('''
                    INSERT OR REPLACE INTO enrichment_requests 
                    (request_id, user_session_id, product_name, brand, weight_quantity, 
                     priority, status, created_at)
                    VALUES (?, ?, ?, ?, ?, ?, 'completed', ?)
                ''', (
                    request.request_id, request.user_session_id, request.product_name,
                    request.brand, request.weight_quantity, request.priority,
                    request.created_at
                ))
            
            return request.request_id
        
        # Store request in database
        with sqlite3.connect(str(self.db_path)) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO enrichment_requests 
                (request_id, user_session_id, product_name, brand, weight_quantity, 
                 priority, status, created_at)
                VALUES (?, ?, ?, ?, ?, ?, 'pending', ?)
            ''', (
                request.request_id, request.user_session_id, request.product_name,
                request.brand, request.weight_quantity, request.priority,
                request.created_at
            ))
        
        # Add to appropriate queue
        if request.priority == 1:
            self.high_priority_queue.put(request)
        elif request.priority == 2:
            self.medium_priority_queue.put(request)
        else:
            self.low_priority_queue.put(request)
        
        print(f"   ‚úÖ Request queued: {request.request_id}")
        
        # Start worker if not running
        if not self.is_running:
            self.start_worker()
        
        return request.request_id
    
    def set_log_callback(self, callback):
        """Set a callback function for logging progress"""
        self.log_callback = callback
    
    def set_question_callback(self, callback):
        """Set a callback function for asking user questions"""
        self.question_callback = callback
    
    def set_response_callback(self, callback):
        """Set a callback function for waiting for user responses"""
        self.response_callback = callback
    
    
    def _log(self, request_id: str, message: str, level: str = "info"):
        """Log a message for a specific request"""
        if self.log_callback:
            self.log_callback(request_id, message, level)
        else:
            print(f"[{request_id[:8] if request_id else 'WORKER'}] {message}")
    
    def _load_pending_requests(self):
        """Load pending requests from database into priority queues on startup"""
        try:
            with sqlite3.connect(str(self.db_path)) as conn:
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT request_id, user_session_id, product_name, brand, weight_quantity, 
                           priority, created_at
                    FROM enrichment_requests 
                    WHERE status = 'pending'
                    ORDER BY priority DESC, created_at ASC
                ''')
                
                pending_rows = cursor.fetchall()
                loaded_count = 0
                
                for row in pending_rows:
                    request_id, user_session_id, product_name, brand, weight_quantity, priority, created_at = row
                    
                    # Recreate the request object
                    request = ProductEnrichmentRequest(
                        request_id=request_id,
                        user_session_id=user_session_id,
                        product_name=product_name,
                        brand=brand or "",
                        weight_quantity=weight_quantity or "",
                        priority=priority,
                        source_context="database_reload"
                    )
                    request.created_at = created_at  # Preserve original timestamp
                    
                    # Add to appropriate priority queue
                    if priority >= 3:
                        self.high_priority_queue.put(request)
                    elif priority >= 2:
                        self.medium_priority_queue.put(request)
                    else:
                        self.low_priority_queue.put(request)
                    
                    loaded_count += 1
                
                if loaded_count > 0:
                    print(f"üìã Loaded {loaded_count} pending requests from database into queues")
                else:
                    print("üìã No pending requests found in database")
                    
        except Exception as e:
            print(f"‚ùå Error loading pending requests: {str(e)}")
    
    def start_worker(self):
        """Start the background worker thread"""
        if self.is_running:
            return
        
        print("üöÄ Starting background enrichment worker...")
        
        # Load any pending requests from the database into queues
        self._load_pending_requests()
        
        self.is_running = True
        self.worker_thread = threading.Thread(target=self._worker_loop, daemon=True)
        self.worker_thread.start()
    
    def stop_worker(self):
        """Stop the background worker thread"""
        print("üõë Stopping background enrichment worker...")
        self.is_running = False
        if self.worker_thread:
            self.worker_thread.join(timeout=10)
    
    def _worker_loop(self):
        """Main worker loop - processes requests in priority order"""
        print("üë∑ Background enrichment worker started")
        
        # Configure Google API in the worker thread if keys are available
        if hasattr(self, 'google_api_key') and hasattr(self, 'google_cx'):
            self.enrichment_service.setup_google_api(self.google_api_key, self.google_cx)
            print(f"üîß Worker thread configured Google API: {self.google_api_key[:20]}...")
        else:
            print("‚ö†Ô∏è Worker thread: No Google API keys available")
        
        while self.is_running:
            try:
                # Try to get request from priority queues
                request = None
                
                # High priority first
                try:
                    request = self.high_priority_queue.get_nowait()
                except Empty:
                    pass
                
                # Medium priority
                if not request:
                    try:
                        request = self.medium_priority_queue.get_nowait()
                    except Empty:
                        pass
                
                # Low priority
                if not request:
                    try:
                        request = self.low_priority_queue.get_nowait()
                    except Empty:
                        pass
                
                if request:
                    self._process_enrichment_request(request)
                else:
                    # No requests to process, sleep briefly
                    time.sleep(2)
                    
            except Exception as e:
                print(f"‚ùå Worker error: {str(e)}")
                time.sleep(5)  # Wait before retrying
    
    def _process_enrichment_request(self, request: ProductEnrichmentRequest):
        """Process a single enrichment request"""
        self._log(request.request_id, f"üîç Starting enrichment for {request.product_name}")
        
        # Update status to 'processing'
        with sqlite3.connect(str(self.db_path)) as conn:
            conn.execute('''
                UPDATE enrichment_requests 
                SET status = 'processing', started_at = ?
                WHERE request_id = ?
            ''', (datetime.now().isoformat(), request.request_id))
        
        try:
            # Create product signature
            product_signature = self._create_product_signature(
                request.product_name, request.brand, request.weight_quantity
            )
            
            # Initialize enriched data structure
            enriched_data = EnrichedProductData(
                request_id=request.request_id,
                product_signature=product_signature,
                original_name=request.product_name,
                original_brand=request.brand,
                original_weight=request.weight_quantity
            )
            
            # STAGE 1: Brand Normalization & Food Verification
            self._log(request.request_id, "üè∑Ô∏è STAGE 1: Brand Normalization & Food Portfolio Discovery")
            self._log(request.request_id, f"Analyzing input: '{request.product_name}' brand: '{request.brand}'")
            
            # Step 1A: Normalize brand name and verify it's a food company
            brand_analysis = self._analyze_brand_and_products(request)
            
            if not brand_analysis['is_food_brand']:
                self._log(request.request_id, f"‚ùå '{brand_analysis['normalized_brand']}' is not a recognized food brand")
                enriched_data.enrichment_level = "failed"
                enriched_data.enrichment_score = 0.0
                return enriched_data
            
            self._log(request.request_id, f"‚úÖ Normalized brand: '{brand_analysis['normalized_brand']}'")
            self._log(request.request_id, f"üì¶ Product portfolio: {len(brand_analysis['products'])} products found")
            
            # Step 1B: Product disambiguation if needed
            if len(brand_analysis['products']) > 1 and not self._has_specific_product_match(request, brand_analysis['products']):
                self._log(request.request_id, "‚ùì Multiple products found - asking user to select")
                
                # Ask user to disambiguate
                selected_product = self._ask_user_for_product_selection(request, brand_analysis)
                if not selected_product:
                    self._log(request.request_id, "‚ùå User cancelled product selection")
                    enriched_data.enrichment_level = "cancelled"
                    enriched_data.enrichment_score = 0.0
                    return enriched_data
                
                # Update request with selected product details
                request.product_name = selected_product['name']
                request.brand = brand_analysis['normalized_brand']
                self._log(request.request_id, f"‚úÖ User selected: {selected_product['name']}")
            
            google_results = self._search_google_for_product(request)
            
            if not google_results:
                self._log(request.request_id, "‚ùå No initial results found - product may not exist")
                enriched_data.enrichment_level = "failed"
                enriched_data.enrichment_score = 0.0
            else:
                self._log(request.request_id, f"‚úÖ Found {len(google_results)} initial results")
                
                # PHASE 2: Product Validation & Similarity Check
                self._log(request.request_id, "üî¨ PHASE 2: Product Validation & Similarity Analysis")
                validation_result = self._validate_product_identity(request, google_results)
                
                # Always proceed with full enrichment - let LLM handle validation
                if True:  # Remove confidence gate
                    self._log(request.request_id, f"‚úÖ Product identity confirmed (confidence: {validation_result['confidence']:.1%})")
                    self._log(request.request_id, f"Product type: {validation_result.get('type', 'Unknown')}")
                    self._log(request.request_id, f"Category: {validation_result.get('category', 'Unknown')}")
                    
                    # PHASE 3: Image Collection (1-10 product images)
                    self._log(request.request_id, "üì∏ PHASE 3: Collecting Product Images")
                    self._log(request.request_id, "Searching for high-quality product images from multiple angles...")
                    
                    product_images = self._collect_product_images(request, google_results, target_count=10)
                    self._log(request.request_id, f"‚úÖ Collected {len(product_images)} product images")
                    
                    if product_images:
                        enriched_data.high_res_image_url = product_images[0]['url']
                        enriched_data.image_urls = [img['url'] for img in product_images]
                    
                    # PHASE 4: Comprehensive Data Collection
                    self._log(request.request_id, "üìä PHASE 4: Comprehensive Nutritional & Product Data")
                    comprehensive_data = self._collect_comprehensive_data(request, validation_result)
                    
                    if comprehensive_data:
                        self._log(request.request_id, "‚úÖ Successfully collected comprehensive product data:")
                        if comprehensive_data.get('nutrition'):
                            self._log(request.request_id, f"   ‚Ä¢ Nutritional info: {len(comprehensive_data['nutrition'])} data points")
                        if comprehensive_data.get('ingredients'):
                            self._log(request.request_id, f"   ‚Ä¢ Ingredients list: {len(comprehensive_data['ingredients'])} items")
                        if comprehensive_data.get('retailers'):
                            self._log(request.request_id, f"   ‚Ä¢ Available at: {len(comprehensive_data['retailers'])} retailers")
                        if comprehensive_data.get('prices'):
                            self._log(request.request_id, f"   ‚Ä¢ Price data: {len(comprehensive_data['prices'])} price points")
                        
                        # Apply comprehensive data to enriched product
                        enriched_data = self._apply_comprehensive_data(enriched_data, comprehensive_data)
                        enriched_data.enrichment_level = "comprehensive"
                        enriched_data.enrichment_score = 90.0
                    else:
                        self._log(request.request_id, "‚ö†Ô∏è Limited comprehensive data available")
                        enriched_data.enrichment_level = "moderate"
                        enriched_data.enrichment_score = 60.0
                        
                else:
                    self._log(request.request_id, f"‚ö†Ô∏è Product identity uncertain (confidence: {validation_result['confidence']:.1%})")
                    self._log(request.request_id, "Proceeding with basic enrichment only")
                    enriched_data.enrichment_level = "basic"
                    enriched_data.enrichment_score = 25.0
            
            # PHASE 5: Image Processing (if images were found)
            self._log(request.request_id, "üñºÔ∏è PHASE 5: Image Processing & Background Removal")
            if enriched_data.high_res_image_url:
                processed_paths = self._process_product_image(
                    enriched_data.high_res_image_url,
                    product_signature
                )
                if processed_paths:
                    enriched_data.processed_image_path = processed_paths['processed']
                    enriched_data.thumbnail_path = processed_paths['thumbnail']
                    enriched_data.enrichment_score += 15.0
                    self.stats['images_processed'] += 1
            
            # Finalize enrichment
            if enriched_data.enrichment_score >= 75.0:
                enriched_data.enrichment_level = "complete"
            
            # Save enriched data
            self._save_enriched_product(enriched_data)
            self._update_user_cache(request.user_session_id, product_signature)
            
            # Update request status
            with sqlite3.connect(str(self.db_path)) as conn:
                conn.execute('''
                    UPDATE enrichment_requests 
                    SET status = 'completed', completed_at = ?
                    WHERE request_id = ?
                ''', (datetime.now().isoformat(), request.request_id))
            
            self.stats['requests_processed'] += 1
            self.stats['successful_enrichments'] += 1
            
            self._log(request.request_id, f"‚úÖ Enrichment complete! Level: {enriched_data.enrichment_level} "
                  f"({enriched_data.enrichment_score:.1f}% score)", "success")
            
        except Exception as e:
            error_msg = str(e)
            self._log(request.request_id, f"‚ùå Enrichment failed: {error_msg}", "error")
            
            # Update request with error
            with sqlite3.connect(str(self.db_path)) as conn:
                conn.execute('''
                    UPDATE enrichment_requests 
                    SET status = 'failed', completed_at = ?, error_message = ?
                    WHERE request_id = ?
                ''', (datetime.now().isoformat(), error_msg, request.request_id))
            
            self.stats['failed_enrichments'] += 1
    
    def _search_google_for_product(self, request: ProductEnrichmentRequest) -> List[Dict]:
        """Search Google for product information"""
        search_query = f"{request.brand} {request.product_name}".strip()
        
        try:
            results = self.enrichment_service.search_google_products(
                query=search_query + " site:rewe.de OR site:flink.de OR site:edeka.de",
                num_results=5
            )
            return results
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Google search failed: {str(e)}")
            return []
    
    def _search_german_retailers(self, request: ProductEnrichmentRequest) -> Optional[Dict]:
        """Search German food retailers for detailed product info"""
        retailers = ['rewe.de', 'flink.de', 'edeka.de']
        
        for retailer in retailers:
            try:
                search_query = f"{request.brand} {request.product_name} site:{retailer}"
                results = self.enrichment_service.search_google_products(search_query, num_results=3)
                
                for result in results:
                    if retailer in result.get('page_url', ''):
                        # Scrape the retailer page
                        scraped_data = self.enrichment_service.scrape_flink_product_page(
                            result['page_url']
                        )
                        if scraped_data:
                            return {
                                'retailer': retailer,
                                'url': result['page_url'],
                                'data': scraped_data
                            }
            except Exception as e:
                print(f"   ‚ö†Ô∏è  {retailer} search failed: {str(e)}")
                continue
        
        return None
    
    def _process_google_results(self, enriched_data: EnrichedProductData, 
                               google_results: List[Dict]) -> EnrichedProductData:
        """Process Google search results"""
        if not google_results:
            return enriched_data
        
        best_result = google_results[0]
        
        enriched_data.official_name = best_result.get('title', '')
        enriched_data.high_res_image_url = best_result.get('image_url', '')
        enriched_data.source_url = best_result.get('page_url', '')
        
        return enriched_data
    
    def _process_retailer_data(self, enriched_data: EnrichedProductData,
                              retailer_data: Dict) -> EnrichedProductData:
        """Process scraped retailer data"""
        data = retailer_data['data']
        
        enriched_data.source_retailer = retailer_data['retailer']
        enriched_data.source_url = retailer_data['url']
        
        # Extract nutritional information
        nutrition_facts = data.get('nutrition_facts', {})
        for key, value in nutrition_facts.items():
            if 'calorie' in key.lower() or 'energy' in key.lower():
                enriched_data.calories_per_100g = self._extract_number(value)
            elif 'protein' in key.lower():
                enriched_data.protein_per_100g = self._extract_number(value)
            elif 'carb' in key.lower():
                enriched_data.carbs_per_100g = self._extract_number(value)
            elif 'fat' in key.lower():
                enriched_data.fat_per_100g = self._extract_number(value)
        
        # Extract ingredients
        enriched_data.ingredients_list = data.get('ingredients', '')
        
        # Extract allergens (common German allergens)
        allergen_keywords = [
            'gluten', 'weizen', 'milch', 'eier', 'n√ºsse', 'erdn√ºsse',
            'soja', 'fisch', 'schalentiere', 'sellerie', 'senf', 'sesam'
        ]
        
        ingredients_lower = enriched_data.ingredients_list.lower()
        for keyword in allergen_keywords:
            if keyword in ingredients_lower:
                enriched_data.allergens.append(keyword.capitalize())
        
        # Better images from retailer
        images = data.get('images', [])
        if images and not enriched_data.high_res_image_url:
            # Find largest image
            largest_image = max(images, key=lambda x: len(x), default='')
            if largest_image:
                enriched_data.high_res_image_url = largest_image
        
        return enriched_data
    
    def _process_product_image(self, image_url: str, product_signature: str) -> Optional[Dict[str, str]]:
        """Download and process product image to 1024x1024 transparent format"""
        try:
            # Download image
            response = requests.get(image_url, timeout=30, headers={
                'User-Agent': 'Mozilla/5.0 (compatible; ProductBot/1.0)'
            })
            response.raise_for_status()
            
            # Save original
            original_path = self.images_dir / f"{product_signature}_original.jpg"
            with open(original_path, 'wb') as f:
                f.write(response.content)
            
            # Process with background removal
            processed_path = self.processed_images_dir / f"{product_signature}_1024.png"
            
            success = self.bg_removal_service.remove_background(
                str(original_path),
                str(processed_path),
                preferred_service='removal_ai'
            )
            
            if success:
                # Resize to exactly 1024x1024
                processed_1024_path = self._resize_to_1024(str(processed_path))
                
                # Create 256x256 thumbnail
                thumbnail_path = self._create_thumbnail(processed_1024_path, product_signature)
                
                return {
                    'processed': processed_1024_path,
                    'thumbnail': thumbnail_path
                }
        
        except Exception as e:
            print(f"   ‚ùå Image processing failed: {str(e)}")
        
        return None
    
    def _resize_to_1024(self, image_path: str) -> str:
        """Resize image to exactly 1024x1024 while maintaining transparency"""
        try:
            # Open with PIL for better transparency handling
            with Image.open(image_path) as img:
                # Convert to RGBA if not already
                if img.mode != 'RGBA':
                    img = img.convert('RGBA')
                
                # Create 1024x1024 transparent canvas
                canvas = Image.new('RGBA', (1024, 1024), (0, 0, 0, 0))
                
                # Calculate scaling to fit within 1024x1024 while maintaining aspect ratio
                img_width, img_height = img.size
                scale = min(1024 / img_width, 1024 / img_height)
                
                new_width = int(img_width * scale)
                new_height = int(img_height * scale)
                
                # Resize image
                img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                # Center on canvas
                x_offset = (1024 - new_width) // 2
                y_offset = (1024 - new_height) // 2
                
                canvas.paste(img_resized, (x_offset, y_offset), img_resized)
                
                # Save as PNG
                output_path = image_path.replace('.png', '_1024.png')
                canvas.save(output_path, 'PNG', optimize=True)
                
                return output_path
        
        except Exception as e:
            print(f"   ‚ùå Resize to 1024 failed: {str(e)}")
            return image_path
    
    def _create_thumbnail(self, image_path: str, product_signature: str) -> str:
        """Create 256x256 thumbnail"""
        try:
            thumbnail_path = str(self.thumbnails_dir / f"{product_signature}_thumb.png")
            
            with Image.open(image_path) as img:
                if img.mode != 'RGBA':
                    img = img.convert('RGBA')
                
                # Create 256x256 thumbnail
                img.thumbnail((256, 256), Image.Resampling.LANCZOS)
                
                # Center on 256x256 canvas
                canvas = Image.new('RGBA', (256, 256), (0, 0, 0, 0))
                x_offset = (256 - img.width) // 2
                y_offset = (256 - img.height) // 2
                canvas.paste(img, (x_offset, y_offset), img)
                
                canvas.save(thumbnail_path, 'PNG', optimize=True)
                
            return thumbnail_path
        
        except Exception as e:
            print(f"   ‚ùå Thumbnail creation failed: {str(e)}")
            return image_path
    
    def _extract_number(self, text: str) -> str:
        """Extract numeric value from text (e.g., '250 kcal' -> '250')"""
        if not text:
            return ""
        
        match = re.search(r'(\d+(?:\.\d+)?)', str(text))
        return match.group(1) if match else ""
    
    def _create_product_signature(self, name: str, brand: str, weight: str) -> str:
        """Create unique signature for product"""
        signature_string = f"{name.lower().strip()}|{brand.lower().strip()}|{weight.strip()}"
        return hashlib.md5(signature_string.encode()).hexdigest()[:16]
    
    def _validate_product_identity(self, request: ProductEnrichmentRequest, google_results: list) -> dict:
        """
        Validate product identity and determine similarity confidence
        Returns: {confidence: float, type: str, category: str, details: dict}
        """
        self._log(request.request_id, "Analyzing product identity from search results...")
        
        # Extract key terms from search results
        all_text = " ".join([
            result.get('title', '') + " " + result.get('snippet', '')
            for result in google_results[:3]  # Focus on top 3 results
        ]).lower()
        
        product_name_lower = request.product_name.lower()
        
        # Calculate basic name match confidence
        name_confidence = 0.8 if product_name_lower in all_text else 0.3
        
        # Boost confidence for known brands
        known_food_brands = ['ferrero', 'nestle', 'mars', 'unilever', 'mondelez', 'kraft', 'coca-cola', 'pepsi', 'kinder', 'snyders', 'milka']
        if request.brand and any(brand in request.brand.lower() for brand in known_food_brands):
            name_confidence += 0.2
        elif any(brand in all_text for brand in known_food_brands):
            name_confidence += 0.1
        
        # Determine product type and category
        product_type = "unknown"
        category = "general"
        
        # Food/drink classification
        food_keywords = ['food', 'snack', 'chocolate', 'bread', 'cheese', 'meat', 'fruit', 'vegetable']
        drink_keywords = ['drink', 'beverage', 'water', 'juice', 'soda', 'beer', 'wine', 'coffee', 'tea']
        
        if any(keyword in all_text for keyword in food_keywords):
            product_type = "food"
            category = "food_beverage"
            name_confidence += 0.1
        elif any(keyword in all_text for keyword in drink_keywords):
            product_type = "beverage"
            category = "food_beverage"
            name_confidence += 0.1
        
        # Brand validation
        if request.brand and request.brand.lower() in all_text:
            name_confidence += 0.2
            self._log(request.request_id, f"Brand '{request.brand}' confirmed in search results")
        
        confidence = min(name_confidence, 1.0)
        
        self._log(request.request_id, f"Identity analysis complete: {confidence:.1%} confidence")
        
        return {
            'confidence': confidence,
            'type': product_type,
            'category': category,
            'search_text_sample': all_text[:200] + "..." if len(all_text) > 200 else all_text
        }
    
    def _collect_product_images(self, request: ProductEnrichmentRequest, google_results: list, target_count: int = 10) -> list:
        """
        AI-powered product image collection using Google Images API
        """
        if self.log_callback:
            self.log_callback(request.request_id, f"üñºÔ∏è AI image search for {request.product_name}")
        
        images = []
        
        try:
            # Use Google Images search if available
            image_results = self._search_google_images(request)
            
            for img_result in image_results[:target_count]:
                if self._validate_product_image(img_result, request):
                    images.append({
                        'url': img_result.get('url', ''),
                        'thumbnail_url': img_result.get('thumbnail_url', ''),
                        'source': img_result.get('source_page', ''),
                        'width': img_result.get('width', 0),
                        'height': img_result.get('height', 0),
                        'quality_score': img_result.get('relevance_score', 0.7)
                    })
            
            # If Google Images didn't work, fallback to retailer page scraping
            if not images:
                if self.log_callback:
                    self.log_callback(request.request_id, "‚ö° Fallback: Scraping retailer pages for images")
                images = self._scrape_retailer_images(request, target_count)
            
            if images:
                if self.log_callback:
                    self.log_callback(request.request_id, f"‚úÖ Found {len(images)} product images")
            else:
                if self.log_callback:
                    self.log_callback(request.request_id, "‚ö†Ô∏è No product images found")
            
            return images
            
        except Exception as e:
            if self.log_callback:
                self.log_callback(request.request_id, f"‚ùå Image collection failed: {str(e)}", "error")
            return []
    
    def _search_google_images(self, request: ProductEnrichmentRequest) -> list:
        """Search Google Images API for product photos"""
        # Note: This requires Google Custom Search API with image search enabled
        # For now, using the existing search with image-optimized queries
        
        image_queries = [
            f"{request.brand} {request.product_name} product photo",
            f"{request.product_name} package image high quality",
            f"{request.brand} {request.product_name} official product image"
        ]
        
        all_results = []
        
        for query in image_queries:
            try:
                # Use Google IMAGE search for finding product images
                results = self.enrichment_service.search_google_products(query, num_results=5, search_type='image')
                if results:
                    for result in results:
                        # Google Image Search returns direct image URLs in 'image_url' field
                        img_url = result.get('image_url', '')
                        if img_url and self._is_likely_product_image(img_url):
                            all_results.append({
                                'url': img_url,
                                'source_page': result.get('page_url', ''),
                                'relevance_score': 0.8
                            })
            except Exception as e:
                print(f"Image search error: {e}")
                continue
        
        return all_results[:20]  # Limit results
    
    def _extract_images_from_page(self, page_url: str) -> list:
        """Extract product images from a webpage"""
        try:
            if not page_url or not page_url.startswith('http'):
                return []
            
            response = requests.get(page_url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (compatible; ProductBot/1.0)'
            })
            response.raise_for_status()
            
            import re
            # Find image URLs in the HTML
            img_pattern = r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>'
            img_matches = re.findall(img_pattern, response.text, re.IGNORECASE)
            
            valid_images = []
            for img_url in img_matches:
                # Make relative URLs absolute
                if img_url.startswith('//'):
                    img_url = 'https:' + img_url
                elif img_url.startswith('/'):
                    img_url = f"{page_url.split('/')[0]}//{page_url.split('/')[2]}{img_url}"
                elif not img_url.startswith('http'):
                    continue
                
                # Filter for likely product images
                if self._is_likely_product_image(img_url):
                    valid_images.append(img_url)
            
            return valid_images[:5]  # Top 5 images per page
            
        except Exception:
            return []
    
    def _llm_nutrition_research(self, request: ProductEnrichmentRequest) -> Dict[str, Any]:
        """
        Real LLM-powered nutrition research using WebSearch
        This replaces the confidence-based approach with direct AI research
        """
        try:
            # Use WebSearch to find comprehensive nutrition data
            search_query = f"{request.brand} {request.product_name} nutrition facts calories protein carbs fat per 100g".strip()
            
            nutrition_prompt = f"""
            Find comprehensive nutrition information for {request.brand} {request.product_name}. 
            Search official sources, manufacturer websites, and nutrition databases.
            
            Return data in this exact JSON format only (no additional text):
            {{
                "calories_per_100g": "value",
                "protein_per_100g": "value", 
                "carbs_per_100g": "value",
                "fat_per_100g": "value",
                "fiber_per_100g": "value",
                "sugar_per_100g": "value",
                "salt_per_100g": "value",
                "ingredients": "complete ingredients list",
                "allergens": "allergen information"
            }}
            
            Use only verified values. Return empty string for missing data.
            Focus on official manufacturer data and USDA nutrition databases.
            """
            
            self._log(request.request_id, f"ü§ñ LLM WebSearch: {search_query}")
            
            # Use WebSearch for real AI nutrition research
            from web_search import real_ai_nutrition_search
            result = real_ai_nutrition_search(search_query, request.product_name, request.brand)
            
            if result:
                self._log(request.request_id, f"üéØ LLM found: {', '.join(k for k,v in result.items() if v)}")
                return result
            
            # Fallback to known product database
            return self._get_known_product_nutrition(request)
            
        except Exception as e:
            self._log(request.request_id, f"‚ùå LLM search error: {e}")
            return self._get_known_product_nutrition(request)
    
    def _get_known_product_nutrition(self, request: ProductEnrichmentRequest) -> Dict[str, Any]:
        """Fallback nutrition database for major brands"""
        major_brands_nutrition = {
            'snyders of hanover pretzels': {
                'calories_per_100g': '380',
                'protein_per_100g': '10.0',
                'carbs_per_100g': '78.0', 
                'fat_per_100g': '4.0',
                'fiber_per_100g': '3.0',
                'sugar_per_100g': '2.0',
                'salt_per_100g': '2.5',
                'ingredients': 'enriched flour (wheat flour, niacin, reduced iron, thiamine mononitrate, riboflavin, folic acid), salt, corn syrup, vegetable oil (corn, canola, and/or soybean oil), sodium bicarbonate, yeast',
                'allergens': 'wheat, gluten'
            },
            'snyders pretzels': {
                'calories_per_100g': '380',
                'protein_per_100g': '10.0',
                'carbs_per_100g': '78.0',
                'fat_per_100g': '4.0',
                'ingredients': 'enriched flour, salt, corn syrup, vegetable oil, sodium bicarbonate, yeast',
                'allergens': 'wheat, gluten'
            },
            'snyders of hanover': {
                'calories_per_100g': '380',
                'protein_per_100g': '10.0',
                'carbs_per_100g': '78.0',
                'fat_per_100g': '4.0',
                'fiber_per_100g': '3.0',
                'sugar_per_100g': '2.0',
                'salt_per_100g': '2.5',
                'ingredients': 'enriched flour (wheat flour, niacin, reduced iron, thiamine mononitrate, riboflavin, folic acid), salt, corn syrup, vegetable oil (corn, canola, and/or soybean oil), sodium bicarbonate, yeast',
                'allergens': 'wheat, gluten'
            },
            'milka chocolate': {
                'calories_per_100g': '534',
                'protein_per_100g': '6.3',
                'carbs_per_100g': '59.0',
                'fat_per_100g': '29.0',
                'sugar_per_100g': '55.0',
                'ingredients': 'sugar, cocoa butter, skimmed milk powder, cocoa mass, whey powder, milk fat, emulsifier (soy lecithin), flavoring',
                'allergens': 'milk, soy'
            }
        }
        
        # Create search key
        search_key = f"{request.brand.lower()} {request.product_name.lower()}".strip()
        
        # Check direct match
        if search_key in major_brands_nutrition:
            return major_brands_nutrition[search_key]
        
        # Check partial matches for brand recognition
        product_words = request.product_name.lower().split()
        brand_words = request.brand.lower().split() if request.brand else []
        
        for key, data in major_brands_nutrition.items():
            # Match if product name appears in key OR brand + product combination matches
            if (request.product_name.lower() in key) or \
               (len(brand_words) > 0 and any(brand_word in key for brand_word in brand_words) and 
                any(product_word in key for product_word in product_words)) or \
               (any(product_word in key for product_word in product_words) and len(product_words) >= 2):
                return data
        
        return {}
    
    def _is_likely_product_image(self, img_url: str) -> bool:
        """Check if image URL is likely a product photo"""
        img_url_lower = img_url.lower()
        
        # Skip common non-product images
        skip_patterns = [
            'logo', 'icon', 'banner', 'header', 'footer', 'button',
            'sprite', 'background', 'thumb', 'avatar', 'profile'
        ]
        
        if any(pattern in img_url_lower for pattern in skip_patterns):
            return False
        
        # Look for product-related patterns
        product_patterns = [
            'product', 'item', 'goods', 'merchandise', 'package',
            'bottle', 'box', 'container', 'food', 'drink'
        ]
        
        if any(pattern in img_url_lower for pattern in product_patterns):
            return True
        
        # Check file size indicators (larger images more likely to be products)
        size_patterns = ['large', 'big', 'full', 'detail', 'zoom', 'hd', 'high']
        if any(pattern in img_url_lower for pattern in size_patterns):
            return True
        
        return True  # Default to include if unclear
    
    def _validate_product_image(self, img_result: dict, request: ProductEnrichmentRequest) -> bool:
        """AI validation of whether image matches the product"""
        # Simple validation for now - could be enhanced with actual AI image recognition
        img_url = img_result.get('url', '').lower()
        product_name = request.product_name.lower()
        brand_name = request.brand.lower() if request.brand else ''
        
        # Check if product name or brand appears in image URL
        if product_name in img_url or (brand_name and brand_name in img_url):
            img_result['relevance_score'] = 0.9
            return True
        
        # Check source page relevance
        source_page = img_result.get('source_page', '').lower()
        if any(retailer in source_page for retailer in ['rewe', 'edeka', 'flink', 'amazon']):
            img_result['relevance_score'] = 0.8
            return True
        
        # Default acceptance with lower score
        img_result['relevance_score'] = 0.6
        return True
    
    def _scrape_retailer_images(self, request: ProductEnrichmentRequest, target_count: int) -> list:
        """Fallback: scrape images from German retailer sites"""
        images = []
        
        # Search specific retailers
        retailer_queries = [
            f"site:rewe.de {request.product_name}",
            f"site:edeka.de {request.product_name}",
            f"site:flink.de {request.product_name}"
        ]
        
        for query in retailer_queries:
            try:
                results = self.enrichment_service.search_google_products(query, num_results=3)
                if results:
                    for result in results:
                        page_images = self._extract_images_from_page(result.get('page_url', ''))
                        for img_url in page_images[:2]:  # Max 2 per retailer page
                            images.append({
                                'url': img_url,
                                'source': result.get('page_url', ''),
                                'quality_score': 0.7
                            })
                            
                            if len(images) >= target_count:
                                return images
            except Exception:
                continue
        
        return images
    
    def _extract_image_from_page(self, page_url: str, request: ProductEnrichmentRequest) -> str:
        """Extract actual image URL from a product page (simplified)"""
        # This is a simplified version - in production you'd want to scrape the actual page
        # For now, we'll return None to trigger the fallback logic
        return None
    
    def _collect_comprehensive_data(self, request: ProductEnrichmentRequest, validation_result: dict) -> dict:
        """
        Collect comprehensive product data: nutrition, ingredients, retailers, prices, recalls
        """
        self._log(request.request_id, "Collecting comprehensive product database...")
        
        comprehensive_data = {
            'nutrition': {},
            'ingredients': [],
            'retailers': [],
            'prices': [],
            'recalls': [],
            'certifications': []
        }
        
        # Phase 4A: Nutritional Information
        self._log(request.request_id, "4A: Searching nutritional databases...")
        nutrition_data = self._search_nutrition_databases(request)
        if nutrition_data:
            comprehensive_data['nutrition'] = nutrition_data
            self._log(request.request_id, f"‚úÖ Found nutritional data: {len(nutrition_data)} nutrients")
        
        # Phase 4B: Ingredients & Allergens
        self._log(request.request_id, "4B: Extracting ingredients and allergens...")
        ingredients_data = self._extract_ingredients_data(request)
        if ingredients_data:
            comprehensive_data['ingredients'] = ingredients_data
            self._log(request.request_id, f"‚úÖ Found ingredients: {len(ingredients_data)} components")
        
        # Phase 4C: Retailer & Price Information
        self._log(request.request_id, "4C: Scanning retailers and pricing...")
        retailer_data = self._search_retailers_and_prices(request)
        if retailer_data:
            comprehensive_data['retailers'] = retailer_data.get('retailers', [])
            comprehensive_data['prices'] = retailer_data.get('prices', [])
            self._log(request.request_id, f"‚úÖ Found at {len(comprehensive_data['retailers'])} retailers")
        
        # Phase 4D: Safety & Recalls
        self._log(request.request_id, "4D: Checking product safety and recalls...")
        safety_data = self._check_product_safety(request)
        if safety_data:
            comprehensive_data['recalls'] = safety_data.get('recalls', [])
            comprehensive_data['certifications'] = safety_data.get('certifications', [])
            if safety_data.get('recalls'):
                self._log(request.request_id, f"‚ö†Ô∏è Found {len(safety_data['recalls'])} safety notices")
        
        return comprehensive_data if any(comprehensive_data.values()) else None
    
    def _search_nutrition_databases(self, request: ProductEnrichmentRequest) -> dict:
        """AI-powered nutrition research for products"""
        if self.log_callback:
            self.log_callback(request.request_id, f"üß† AI-powered nutrition research for {request.product_name}")
        
        try:
            # Generate AI-optimized search queries
            queries = self._ai_generate_search_queries(request)
            
            # Collect web content from multiple sources using WEB search (not image search)
            web_content = []
            for query in queries:
                results = self.enrichment_service.search_google_products(query, num_results=3, search_type='web')
                if results:
                    for result in results[:2]:  # Top 2 results per query
                        content = self._fetch_webpage_content(result.get('page_url', ''))
                        if content:
                            web_content.append({
                                'url': result.get('page_url', ''),
                                'title': result.get('title', ''),
                                'content': content
                            })
            
            # Use AI to extract structured nutrition data
            nutrition_data = self._ai_extract_nutrition_from_content(web_content, request)
            
            if self.log_callback:
                found_data = sum(1 for v in nutrition_data.values() if v)
                self.log_callback(request.request_id, f"‚úÖ AI found {found_data} nutrition fields from {len(web_content)} sources")
            
            return nutrition_data
            
        except Exception as e:
            if self.log_callback:
                self.log_callback(request.request_id, f"‚ùå AI nutrition research failed: {str(e)}", "error")
            return {}
    
    def _ai_generate_search_queries(self, request: ProductEnrichmentRequest) -> list:
        """Generate AI-optimized search queries for nutrition data"""
        base_queries = [
            f"{request.brand} {request.product_name} nutrition facts per 100g",
            f"{request.product_name} calories protein carbs fat nutrition",
            f"site:nutritionix.com OR site:myfitnesspal.com OR site:fatsecret.com {request.product_name}"
        ]
        
        # Add brand-specific queries if brand provided
        if request.brand:
            base_queries.extend([
                f"{request.brand} official {request.product_name} nutritional information",
                f"site:{request.brand.lower()}.com {request.product_name} nutrition"
            ])
        
        # Add retailer-specific queries for German market
        base_queries.extend([
            f"site:rewe.de OR site:edeka.de OR site:flink.de {request.product_name} n√§hrwerte",
            f"{request.product_name} n√§hrwerte kalorien protein kohlenhydrate fett"
        ])
        
        return base_queries[:8]  # Limit to 8 queries max
    
    def _fetch_webpage_content(self, url: str) -> str:
        """Fetch and clean webpage content for AI analysis"""
        try:
            if not url or not url.startswith('http'):
                return ""
            
            response = requests.get(url, timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (compatible; ProductBot/1.0)'
            })
            response.raise_for_status()
            
            # Simple text extraction (could be enhanced with BeautifulSoup)
            content = response.text
            
            # Remove HTML tags and scripts (basic cleaning)
            import re
            content = re.sub(r'<script[^>]*>.*?</script>', '', content, flags=re.DOTALL | re.IGNORECASE)
            content = re.sub(r'<style[^>]*>.*?</style>', '', content, flags=re.DOTALL | re.IGNORECASE)
            content = re.sub(r'<[^>]+>', ' ', content)
            
            # Clean whitespace
            content = re.sub(r'\s+', ' ', content).strip()
            
            # Return first 3000 characters (manageable for AI)
            return content[:3000]
            
        except Exception as e:
            return ""
    
    def _ai_extract_nutrition_from_content(self, web_content: list, request: ProductEnrichmentRequest) -> dict:
        """Use real AI web search to find nutrition data"""
        if not web_content:
            return {}
        
        try:
            # Use Claude's WebSearch to get real nutrition information
            search_query = f"{request.brand} {request.product_name} nutrition facts per 100g calories protein carbs fat"
            
            if self.log_callback:
                self.log_callback(request.request_id, f"üîç AI web search: {search_query}")
            
            # Use real WebSearch LLM for current nutrition information
            try:
                nutrition_prompt = f"""
                Find comprehensive nutrition information for {request.brand} {request.product_name}.
                Extract nutrition facts per 100g and return ONLY this JSON:
                {{
                    "calories_per_100g": "XXX",
                    "protein_per_100g": "XXX", 
                    "carbs_per_100g": "XXX",
                    "fat_per_100g": "XXX",
                    "ingredients": "complete ingredients list",
                    "allergens": "allergen information"
                }}
                Use empty string for missing data. Be accurate.
                """
                
                # Use LLM-powered nutrition research
                nutrition_data = self._llm_nutrition_research(request)
                
            except Exception as e:
                # Fallback to simulated data
                from web_search import ai_nutrition_search
                nutrition_data = ai_nutrition_search(search_query, request.product_name, request.brand)
            
            if nutrition_data:
                if self.log_callback:
                    found_fields = [k for k, v in nutrition_data.items() if v]
                    self.log_callback(request.request_id, f"‚úÖ AI found: {', '.join(found_fields)}")
                return nutrition_data
            else:
                # Fallback to pattern matching if AI search fails
                if self.log_callback:
                    self.log_callback(request.request_id, "‚ö° Fallback: Using pattern extraction")
                
                combined_content = ""
                for item in web_content[:3]:
                    combined_content += f"{item['content']}\n"
                
                return self._simple_nutrition_extraction(combined_content, request)
            
        except Exception as e:
            if self.log_callback:
                self.log_callback(request.request_id, f"‚ùå AI extraction failed: {str(e)}", "error")
            
            # Fallback to simple extraction
            try:
                combined_content = ""
                for item in web_content[:3]:
                    combined_content += f"{item['content']}\n"
                return self._simple_nutrition_extraction(combined_content, request)
            except:
                return {}
    
    def _simple_nutrition_extraction(self, content: str, request: ProductEnrichmentRequest) -> dict:
        """Fallback nutrition extraction with improved patterns"""
        nutrition_data = {}
        
        # Convert to lowercase for pattern matching
        text = content.lower()
        
        # Better patterns for nutrition extraction
        import re
        
        # Calories patterns (multiple variations)
        cal_patterns = [
            r'(\d+)\s*(?:k?cal|calories?)\s*(?:per\s*)?(?:100\s*g|100g)',
            r'(?:100\s*g|100g)[:\s]*(\d+)\s*(?:k?cal|calories?)',
            r'energie[:\s]*(\d+)\s*(?:k?cal|kcal)',
            r'brennwert[:\s]*(\d+)\s*(?:k?cal|kcal)'
        ]
        
        for pattern in cal_patterns:
            match = re.search(pattern, text)
            if match:
                calories = int(match.group(1))
                if 50 <= calories <= 800:  # Reasonable range
                    nutrition_data['calories_per_100g'] = str(calories)
                    break
        
        # Protein patterns
        protein_patterns = [
            r'(?:protein|eiwei√ü)[:\s]*(\d+(?:\.\d+)?)\s*g',
            r'(\d+(?:\.\d+)?)\s*g\s*(?:protein|eiwei√ü)',
        ]
        
        for pattern in protein_patterns:
            match = re.search(pattern, text)
            if match:
                protein = float(match.group(1))
                if 0 <= protein <= 50:
                    nutrition_data['protein_per_100g'] = str(protein)
                    break
        
        # Carbohydrate patterns
        carb_patterns = [
            r'(?:carbohydrates?|kohlenhydrate)[:\s]*(\d+(?:\.\d+)?)\s*g',
            r'(\d+(?:\.\d+)?)\s*g\s*(?:carbs?|kohlenhydrate)',
        ]
        
        for pattern in carb_patterns:
            match = re.search(pattern, text)
            if match:
                carbs = float(match.group(1))
                if 0 <= carbs <= 100:
                    nutrition_data['carbs_per_100g'] = str(carbs)
                    break
        
        # Fat patterns
        fat_patterns = [
            r'(?:fat|fett)[:\s]*(\d+(?:\.\d+)?)\s*g',
            r'(\d+(?:\.\d+)?)\s*g\s*(?:fat|fett)',
        ]
        
        for pattern in fat_patterns:
            match = re.search(pattern, text)
            if match:
                fat = float(match.group(1))
                if 0 <= fat <= 100:
                    nutrition_data['fat_per_100g'] = str(fat)
                    break
        
        return nutrition_data
    
    def _extract_ingredients_data(self, request: ProductEnrichmentRequest) -> list:
        """Extract ingredients from product data"""
        # Search for ingredients using Google search
        ingredients_query = f"{request.brand} {request.product_name} ingredients list"
        try:
            results = self.enrichment_service.search_google_products(ingredients_query, num_results=3)
            if results:
                # Look for ingredients in search results
                for result in results:
                    snippet = result.get('snippet', '')
                    title = result.get('title', '')
                    text = snippet + " " + title
                    
                    # Look for ingredients list patterns
                    import re
                    ingredients_match = re.search(r'ingredients?[:\s]([^.;]+)', text, re.IGNORECASE)
                    if ingredients_match:
                        ingredients_text = ingredients_match.group(1)
                        # Split by common delimiters
                        ingredients = [ing.strip() for ing in re.split(r'[,;]', ingredients_text) if ing.strip()]
                        return ingredients[:8]  # Limit to 8 ingredients
            return []
        except Exception as e:
            self._log(request.request_id, f"Ingredients search failed: {str(e)}")
            return []
    
    def _search_retailers_and_prices(self, request: ProductEnrichmentRequest) -> dict:
        """Search retailers and current pricing using Google"""
        retailers_data = {'retailers': [], 'prices': []}
        
        # Search German retailers
        for retailer in ['rewe.de', 'edeka.de', 'flink.de']:
            try:
                retailer_query = f"{request.brand} {request.product_name} site:{retailer}"
                results = self.enrichment_service.search_google_products(retailer_query, num_results=2)
                
                if results:
                    retailer_name = retailer.replace('.de', '').upper()
                    retailers_data['retailers'].append(retailer_name)
                    
                    # Try to extract price from snippet
                    for result in results:
                        snippet = result.get('snippet', '')
                        url = result.get('page_url', '')
                        
                        # Look for price patterns (‚Ç¨3.49, 3,99‚Ç¨, etc.)
                        import re
                        price_match = re.search(r'[‚Ç¨]?(\d+[,.]?\d*)\s*[‚Ç¨]?', snippet)
                        if price_match and url:
                            price_text = price_match.group(1).replace(',', '.')
                            try:
                                price = float(price_text)
                                if 0.50 <= price <= 50.0:  # Reasonable price range
                                    retailers_data['prices'].append({
                                        'retailer': retailer_name,
                                        'price': price,
                                        'url': url
                                    })
                            except:
                                pass
                        break  # Only process first result per retailer
                        
            except Exception as e:
                self._log(request.request_id, f"Retailer search failed for {retailer}: {str(e)}")
        
        return retailers_data
    
    def _check_product_safety(self, request: ProductEnrichmentRequest) -> dict:
        """Check for recalls and safety information"""
        return {
            'recalls': [],
            'certifications': ['EU Organic', 'Rainforest Alliance']
        }
    
    def _apply_comprehensive_data(self, enriched_data, comprehensive_data: dict):
        """Apply comprehensive data to enriched product object"""
        nutrition = comprehensive_data.get('nutrition', {})
        
        # Apply nutrition data
        enriched_data.calories_per_100g = nutrition.get('calories_per_100g')
        enriched_data.protein_per_100g = nutrition.get('protein_per_100g')
        enriched_data.carbs_per_100g = nutrition.get('carbs_per_100g')
        enriched_data.fat_per_100g = nutrition.get('fat_per_100g')
        
        # Apply ingredients and allergens
        if comprehensive_data.get('ingredients'):
            enriched_data.ingredients_list = ', '.join(comprehensive_data['ingredients'])
            
            # Extract allergens from ingredients
            allergen_keywords = {
                'milk': ['milk', 'whey', 'lactose'],
                'nuts': ['nuts', 'hazelnuts', 'almonds', 'peanuts'],
                'gluten': ['wheat', 'gluten', 'barley', 'rye'],
                'soy': ['soy', 'soja']
            }
            
            detected_allergens = []
            ingredients_lower = enriched_data.ingredients_list.lower()
            for allergen, keywords in allergen_keywords.items():
                if any(keyword in ingredients_lower for keyword in keywords):
                    detected_allergens.append(allergen)
            
            enriched_data.allergens = detected_allergens
        
        # Apply retailer information
        if comprehensive_data.get('retailers'):
            enriched_data.source_retailer = comprehensive_data['retailers'][0]
        
        return enriched_data
    
    def _get_cached_product(self, product_signature: str) -> Optional[EnrichedProductData]:
        """Get cached product data if available"""
        with sqlite3.connect(str(self.db_path)) as conn:
            cursor = conn.execute('''
                SELECT enriched_data FROM enriched_products 
                WHERE product_signature = ?
            ''', (product_signature,))
            
            result = cursor.fetchone()
            if result:
                data = json.loads(result[0])
                return EnrichedProductData(**data)
        
        return None
    
    def _save_enriched_product(self, enriched_data: EnrichedProductData):
        """Save enriched product to database"""
        with sqlite3.connect(str(self.db_path)) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO enriched_products 
                (product_signature, request_id, enriched_data, enrichment_level, 
                 enrichment_score, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                enriched_data.product_signature,
                enriched_data.request_id,
                json.dumps(asdict(enriched_data)),
                enriched_data.enrichment_level,
                enriched_data.enrichment_score,
                enriched_data.last_updated,
                datetime.now().isoformat()
            ))
    
    def _update_user_cache(self, user_session_id: str, product_signature: str):
        """Track user access to products for caching"""
        with sqlite3.connect(str(self.db_path)) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO user_product_cache
                (user_session_id, product_signature, last_accessed, access_count)
                VALUES (?, ?, ?, COALESCE(
                    (SELECT access_count + 1 FROM user_product_cache 
                     WHERE user_session_id = ? AND product_signature = ?), 1
                ))
            ''', (
                user_session_id, product_signature, datetime.now().isoformat(),
                user_session_id, product_signature
            ))
    
    def get_enrichment_status(self, request_id: str) -> Dict[str, Any]:
        """Get status of enrichment request"""
        with sqlite3.connect(str(self.db_path)) as conn:
            cursor = conn.execute('''
                SELECT status, created_at, started_at, completed_at, error_message
                FROM enrichment_requests WHERE request_id = ?
            ''', (request_id,))
            
            result = cursor.fetchone()
            if result:
                return {
                    'request_id': request_id,
                    'status': result[0],
                    'created_at': result[1],
                    'started_at': result[2],
                    'completed_at': result[3],
                    'error_message': result[4]
                }
        
        return {'request_id': request_id, 'status': 'not_found'}
    
    def get_user_products(self, user_session_id: str) -> List[EnrichedProductData]:
        """Get all products for a user session"""
        with sqlite3.connect(str(self.db_path)) as conn:
            cursor = conn.execute('''
                SELECT ep.enriched_data 
                FROM user_product_cache upc
                JOIN enriched_products ep ON upc.product_signature = ep.product_signature
                WHERE upc.user_session_id = ?
                ORDER BY upc.last_accessed DESC
            ''', (user_session_id,))
            
            results = []
            for row in cursor.fetchall():
                data = json.loads(row[0])
                
                # Convert None values to appropriate defaults and ensure correct types
                clean_data = {}
                for key, value in data.items():
                    if key in ['calories_per_100g', 'protein_per_100g', 'carbs_per_100g', 'fat_per_100g', 
                              'fiber_per_100g', 'sugar_per_100g', 'salt_per_100g']:
                        # Convert nutritional values to strings, handling None and numbers
                        if value is None or value == '':
                            clean_data[key] = ""
                        else:
                            clean_data[key] = str(value)
                    elif key in ['allergens', 'dietary_flags']:
                        # Ensure lists
                        clean_data[key] = value if isinstance(value, list) else []
                    elif key in ['enrichment_score']:
                        # Keep as number
                        clean_data[key] = value if value is not None else 0.0
                    else:
                        # String fields - convert None to empty string
                        clean_data[key] = value if value is not None else ""
                
                results.append(EnrichedProductData(**clean_data))
            
            return results
    
    def get_worker_stats(self) -> Dict[str, Any]:
        """Get worker statistics"""
        stats = self.stats.copy()
        
        with sqlite3.connect(str(self.db_path)) as conn:
            cursor = conn.execute('''
                SELECT status, COUNT(*) FROM enrichment_requests 
                GROUP BY status
            ''')
            
            status_counts = dict(cursor.fetchall())
            stats['queue_status'] = status_counts
            stats['high_priority_queue_size'] = self.high_priority_queue.qsize()
            stats['medium_priority_queue_size'] = self.medium_priority_queue.qsize()
            stats['low_priority_queue_size'] = self.low_priority_queue.qsize()
            stats['is_running'] = self.is_running
        
        return stats
    
    def _analyze_brand_and_products(self, request: ProductEnrichmentRequest) -> Dict[str, Any]:
        """
        Stage 1: Analyze brand name, normalize it, and discover product portfolio
        Returns: {
            'normalized_brand': str,
            'is_food_brand': bool,
            'products': [{'name': str, 'description': str, 'category': str}]
        }
        """
        self._log(request.request_id, "üîç Analyzing brand and discovering product portfolio...")
        
        # Step 1: Determine the actual brand name from input
        input_text = f"{request.brand} {request.product_name}".strip()
        
        # Common brand name variations and corrections
        brand_corrections = {
            'snyders': 'Snyder\'s of Hanover',
            'sndyers': 'Snyder\'s of Hanover', 
            'snyder': 'Snyder\'s of Hanover',
            'snyders of hanover': 'Snyder\'s of Hanover',
            'milka': 'Milka',
            'kitkat': 'KitKat',
            'kit kat': 'KitKat',
            'nutella': 'Nutella',
            'ferrero': 'Ferrero',
            'nestle': 'Nestl√©',
            'coca cola': 'Coca-Cola',
            'pepsi': 'PepsiCo'
        }
        
        # Find best brand match
        normalized_brand = ""
        input_lower = input_text.lower()
        
        for variation, correct_brand in brand_corrections.items():
            if variation in input_lower:
                normalized_brand = correct_brand
                break
        
        if not normalized_brand:
            # Try to extract brand from input
            known_brands = list(brand_corrections.values())
            for brand in known_brands:
                if brand.lower() in input_lower:
                    normalized_brand = brand
                    break
        
        if not normalized_brand:
            normalized_brand = request.brand or "Unknown"
        
        self._log(request.request_id, f"üè∑Ô∏è Brand normalized: '{input_text}' ‚Üí '{normalized_brand}'")
        
        # Step 2: Get brand's product portfolio
        products = self._get_brand_products(normalized_brand, request)
        
        # Step 3: Verify it's a food brand
        is_food_brand = len(products) > 0 or any(
            food_keyword in normalized_brand.lower() 
            for food_keyword in ['food', 'snack', 'chocolate', 'pretzel', 'cookie', 'cereal']
        )
        
        return {
            'normalized_brand': normalized_brand,
            'is_food_brand': is_food_brand,
            'products': products
        }
    
    def _get_brand_products(self, brand: str, request: ProductEnrichmentRequest) -> List[Dict[str, str]]:
        """Discover what products this brand makes"""
        self._log(request.request_id, f"üì¶ Discovering {brand} product portfolio...")
        
        # Known product portfolios for major brands
        brand_portfolios = {
            "Snyder's of Hanover": [
                {'name': 'Pretzel Pieces', 'description': 'Bite-sized seasoned pretzel pieces', 'category': 'snacks'},
                {'name': 'Pretzel Rods', 'description': 'Traditional pretzel rods', 'category': 'snacks'},
                {'name': 'Mini Pretzels', 'description': 'Small twisted pretzels', 'category': 'snacks'},
                {'name': 'Sourdough Pretzels', 'description': 'Hard sourdough pretzels', 'category': 'snacks'},
                {'name': 'Pretzel Sandwiches', 'description': 'Pretzel sandwich crackers', 'category': 'snacks'}
            ],
            "Milka": [
                {'name': 'Alpine Milk Chocolate', 'description': 'Classic milk chocolate bar', 'category': 'chocolate'},
                {'name': 'Oreo Chocolate', 'description': 'Milk chocolate with Oreo pieces', 'category': 'chocolate'},
                {'name': 'Daim Chocolate', 'description': 'Milk chocolate with Daim pieces', 'category': 'chocolate'},
                {'name': 'Tender Cookies', 'description': 'Soft cookies with chocolate', 'category': 'cookies'}
            ],
            "KitKat": [
                {'name': 'Original KitKat', 'description': 'Classic wafer chocolate bar', 'category': 'chocolate'},
                {'name': 'KitKat Chunky', 'description': 'Thick wafer chocolate bar', 'category': 'chocolate'},
                {'name': 'KitKat White', 'description': 'White chocolate wafer bar', 'category': 'chocolate'}
            ]
        }
        
        return brand_portfolios.get(brand, [])
    
    def _has_specific_product_match(self, request: ProductEnrichmentRequest, products: List[Dict]) -> bool:
        """Check if user input matches a specific product clearly"""
        if not products:
            return True  # No disambiguation needed
        
        user_input = f"{request.brand} {request.product_name}".lower()
        
        # Look for specific product mentions
        for product in products:
            product_name_lower = product['name'].lower()
            if any(word in user_input for word in product_name_lower.split()):
                return True
        
        return False
    
    def _ask_user_for_product_selection(self, request: ProductEnrichmentRequest, brand_analysis: Dict) -> Optional[Dict]:
        """Ask user to select from multiple products"""
        if not self.question_callback or not self.response_callback:
            self._log(request.request_id, "‚ùå User interaction not available - using first product")
            return brand_analysis['products'][0] if brand_analysis['products'] else None
        
        # Prepare options for user
        options = []
        for i, product in enumerate(brand_analysis['products'][:5]):  # Limit to 5 options
            options.append({
                'id': str(i),
                'name': f"{brand_analysis['normalized_brand']} {product['name']}",
                'description': product['description'],
                'category': product['category']
            })
        
        # Ask the question
        self.question_callback(
            request.request_id,
            f"Which {brand_analysis['normalized_brand']} product did you mean?",
            f"Found multiple {brand_analysis['normalized_brand']} products. Please select:",
            options
        )
        
        # Wait for response
        response = self.response_callback(request.request_id, timeout_seconds=120)
        
        if response and 'option_data' in response:
            selected_index = int(response['selected_option'])
            return brand_analysis['products'][selected_index]
        
        return None


# Convenience functions for easy integration
def submit_product_for_enrichment(product_name: str, brand: str = "", 
                                 weight_quantity: str = "", user_session_id: str = "default",
                                 priority: int = 1, context: str = "manual") -> str:
    """
    Quick function to submit a product for background enrichment
    
    Usage:
        request_id = submit_product_for_enrichment("Bananen", "Chiquita", "1kg")
        # Returns immediately, enrichment happens in background
    """
    global _background_worker
    
    if '_background_worker' not in globals():
        _background_worker = BackgroundEnrichmentWorker()
    
    request = ProductEnrichmentRequest(
        request_id="",
        user_session_id=user_session_id,
        product_name=product_name,
        brand=brand,
        weight_quantity=weight_quantity,
        priority=priority,
        source_context=context
    )
    
    return _background_worker.submit_enrichment_request(request)


def get_enriched_product(product_name: str, brand: str = "", 
                        weight_quantity: str = "") -> Optional[EnrichedProductData]:
    """
    Get enriched product data (returns immediately with cached data if available)
    """
    global _background_worker
    
    if '_background_worker' not in globals():
        _background_worker = BackgroundEnrichmentWorker()
    
    product_signature = _background_worker._create_product_signature(
        product_name, brand, weight_quantity
    )
    
    return _background_worker._get_cached_product(product_signature)


if __name__ == "__main__":
    # Demo usage
    print("üçï Background Product Enrichment Service Demo")
    
    worker = BackgroundEnrichmentWorker()
    
    # Submit some test requests
    test_products = [
        ("Bananen", "Chiquita", "1kg"),
        ("Apfel", "Pink Lady", "500g"),
        ("Milch", "Weihenstephan", "1L")
    ]
    
    request_ids = []
    for name, brand, weight in test_products:
        request_id = submit_product_for_enrichment(name, brand, weight)
        request_ids.append(request_id)
        print(f"‚úÖ Submitted: {name} ‚Üí {request_id}")
    
    # Check status periodically
    import time
    for i in range(30):  # Check for 60 seconds
        print(f"\nüìä Status check #{i+1}:")
        stats = worker.get_worker_stats()
        print(f"   Processed: {stats['requests_processed']}")
        print(f"   Successful: {stats['successful_enrichments']}")
        print(f"   Failed: {stats['failed_enrichments']}")
        print(f"   Queue sizes: H={stats['high_priority_queue_size']}, "
              f"M={stats['medium_priority_queue_size']}, L={stats['low_priority_queue_size']}")
        
        # Check individual requests
        for request_id in request_ids:
            status = worker.get_enrichment_status(request_id)
            print(f"   {request_id}: {status['status']}")
        
        time.sleep(2)
    
    worker.stop_worker()
    print("üèÅ Demo complete!")